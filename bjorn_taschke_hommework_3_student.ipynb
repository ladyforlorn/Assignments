{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whorseman/Assignments/blob/main/bjorn_taschke_hommework_3_student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "! [ -e /content ] && pip install -Uqq fastbook\n",
        "import fastbook\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "fastbook.setup_book()"
      ],
      "metadata": {
        "id": "HhmY7I5M8VJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75244390-8183-4d93-8660-47af3bd13e3e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Artificial Neural Networks\n",
        "\n",
        "Please read the introdcution of neuronal networks of the book *Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow*, p. 299-316.\n",
        "\n",
        "Why have neural networks, even though they were invented early on, only now caught on?\n",
        "\n",
        "What is a percepton and a threshold logic unit (TLU)? Try to define a linear function and a step function of your choice, use some values of your choice and explain what might be the result of the percepton. (maybe using max. two TLU's)\n",
        "\n",
        "What is a fully connected layer and a output layer? Why can we easily combine the equations of multiple instances into a fully connected layer?\n",
        "\n",
        "What problem did Marvin Minsky and Seymour Paper highlight that perceptrons could not solve? What is a possible solution?\n",
        "\n",
        "What is a deep neuronal network? What are hidden layers? What means feedforward neural network (FNN).\n",
        "\n",
        "Try to explain how backpropagation works! (In Addition, you can have a look to the following example, which tries manually to compute the backprogation of a simple linear network. https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/ OR you can also read through the Google Colab [04_mnist_basics.ipynb](https://colab.research.google.com/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb#scrollTo=t1DK6o-gckCy))\n",
        "\n",
        "Why do we need activation functions, wouldn't it be easier just using linear functions?\n",
        "\n",
        "## Ideas for the learning portfolio: \n",
        "\n",
        "1) For example, you could train a single TLU to classify iris flowers based on petal length and width in the !!!pyTorch!! environment.\n",
        "\n",
        "2) You could add to our king county housepricing ML project a neuronal network and compare it to the other models. "
      ],
      "metadata": {
        "id": "_Rdj49uwjuoU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   neural networks have only recently caught on because of computational limitations when they were first artificially constructed and because machine learning lead to better results \n",
        "*   TLU is a neural network design that uses numeric values as input and output. In a linear function weights are given to the input values and the weighted sum is then put in a step function. The step function is most commonly the heavyside function which gives a boolean value to the weighted sum based on its sign. A Perceptron combines several TLUs in which every input is linked to every output. It is thus a fully connected layer. This is possible thanks to matrix algebra.\n",
        "*example: z = -1 * x1 + 1 * x2. Heaveside(z) = 0 with x1 = 2 and x2 = 1 and 1 with x1 = 2 and x2 = 1\n",
        "* Minsky et al highlighted that a Perceptron is not able to solve a XOR problem. This can be solved by a multilayer perceptron\n",
        "* A deep neural network contains hidden layers between the input and output layer. Hidden layers consists for example of layers of TLUs in a perceptron\n",
        "*Backpropagation is used to optimize the weights in a deep neural network. First all weights are randomly produced. Then a small batch is forward fed through the network, after which the total error is computed as a difference between the desired output and the actual one. Lastly, gradient decent is used to tweak the weights. In order to do so the derivative of the total error with respect to each weight is calculated and then multiplied by the learning rate and substracted from the old weight to improve it. A simple example for this would be a weight that is \"too low\", so increasing it would lower the total error. This would mean that the derivative of the total error with respect to said weight is negative.\n",
        "* Activation functions are necessary for the backpropagation algorithm to work as a linear function has a constant derivative which compromises the use of gradient decent. \n",
        "\n"
      ],
      "metadata": {
        "id": "6c9cInirGT7v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VWhy_6AwGRKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()"
      ],
      "metadata": {
        "id": "4tF8YDV3T91n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A traditional approach: training a digit classifier and learning pyTorch tensors.\n",
        "\n",
        "For this assignment, I ask you to read the Google Colab [04_mnist_basics.ipynb](https://colab.research.google.com/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb#scrollTo=t1DK6o-gckCy) to the beginning of the chapter *Stochastic Gradient Descent (SGD)*. \n",
        "\n",
        "First, try to summarize what we know about pyTorch tensors by trying to predict whether we have a 1 or a 7 in the MNIST dataset using a traditional rule-based programming approach. Therefore use pyTorch tensors for the entire tasks and fulfill the following steps:\n",
        "\n",
        "1) Randomly split the MNIST dataset (1 and 7) into a training dataset and a test dataset in a ratio of 80:20.\n",
        "\n",
        "2) Instead of using an optimal 1 or 7 with the mean over the training dataset, try to calculate the sum of the distances to all instances in the training set for each instance in the test dataset. You can use the L2 norm. \n",
        "\n",
        "3) For each instance in the test set, decide if it is a 1 or 7 and calculate the precision.\n",
        "\n",
        "Do we get a similar good result?\n"
      ],
      "metadata": {
        "id": "h6OwXNEeed93"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Hrrgv9OVebAH"
      },
      "outputs": [],
      "source": [
        "# YOUR TASK\n",
        "path = untar_data(URLs.MNIST)\n",
        "Path.BASE_PATH = path\n",
        "#path.ls()\n",
        "#(path/'training').ls()\n",
        "\n",
        "#getting 1 and 7\n",
        "ones = (path/'training'/'1').ls().sorted()\n",
        "sevens = (path/'training'/'7').ls().sorted()\n",
        "\n",
        "\n",
        "\n",
        "train_1, val_1 = torch.utils.data.random_split(ones, [0.8, 0.2])\n",
        "train_7, val_7 = torch.utils.data.random_split(sevens, [0.8, 0.2])\n",
        "\n",
        "#creating tensors out of images\n",
        "seven_tensors = [tensor(Image.open(o)) for o in train_7]\n",
        "ones_tensors = [tensor(Image.open(o)) for o in train_1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
        "stacked_ones = torch.stack(ones_tensors).float()/255\n",
        "\n",
        "mean1 = stacked_ones.mean(0)\n",
        "show_image(mean1);\n",
        "tit7 = stacked_sevens[1]\n",
        "\n",
        "mean7 = stacked_sevens.mean(0)\n",
        "show_image(mean7);\n",
        "tit1 = stacked_ones[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "m5I-HxnWyrsH",
        "outputId": "8e064137-32ff-4f42-b87a-9abf66bbffa9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 100x100 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGEAAABhCAYAAADGBs+jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAANrUlEQVR4nO2c624rR3LHf1XdcyEpnYvtrAMnCyTf9zXyCHnKPELeJdgsgmAN22vrRnFmurvyoXpIikfn2PFa0hyLf2AgSqJIqv5T96oWMzPOeFHoS3+AM84kLAJnEhaAMwkLwJmEBeBMwgJwJmEBOJOwAJxJWADiL33iv+m/P+Xn+F3iP8t//KLnnTVhATiTsACcSVgAziQsAGcSFoAzCQvAmYQF4BfnCYuFyKd//xk0Dj9fEh4TvlTFtvLx5y2QlOWTMAtRFNH6OAQkhMNjEdDD84CHRJSD4Pct9VKckFL8Z8XACjY/d/77ZyBtuSRU4UsITkBQaJr6tUW6FoJibQNNBBEs6oG0WXhmUOUppSDZhS8pOxG5wDRhuUBK2DiCGZYz5OwvUb8+FSHLJOHo7kfU73JVJEYIirQN1regivUN1jVYEEz9ApBZXmZIvbslFciGmMFUSUgZUUFSxlQQK1guCLhWWPHPYMU/1xMQsUwS4GB+VJAQnIC2QWLEVh226bGo5FVDXkdMoDSKRaDKSYo/lmJgoFNBs5OiQ0am7MSIICEjIljOiBR/iZyBgJCx/HT/6vJIEDkQIHogoIlI32FNxDY96U1PaZTpMjBtlBKE3OIkwAMiNPn3YTJ0MjRD3BZ0LOiYCapOSFDXktn8ZNcWEz1SrfKba8OySHg04pHDV3Wbb6qURimNUBohN4IFKC2U+PA1JIOpVRmKkyP+PCmCFYUgUA6vD7gJnN8zF54SyyLhY6hagQjEAHEmQMmtkFZgQcg95Nb/ZL5xJYNOghQIak5iMnQSNFUf8hj5xfbR01Nj2STofHd6dGRBQZUSqya0QuqE3LsmpBXkrjrhmYQkaATN4JpgmAphMCyAKZjAnobHTM0+XH0aQpZDws9lvg+e65dJFaLiAq0XsPcJGJAOwn705QwX/nHe8DGBv6roCD5Mso78gwtcKM3sCyCvzDXBDpqgE4iJm6WR/S0vpZqqbO6Up4xMCSs1X8jF84Nih1D1ibBsEqBmtgcBmEjVAKkaIJSIk9EY1rr0939iIBEUf/4MqaGrFDskbaXUiKj+rPz2d/1jWD4JH8GHpsgoESwW/6UCxj55g1nwsxYYkuareAadKxk5H2Xcr90xzyi2j1akmqWZgNJA7s21YJXRdQKDkhSKYEWwQapJESSBTkYYjLBL6JCQ3QjjhA0jlhLkjNULcCKesIa0fBI+9s+LHExS1QaiEWL22J/iBOjBBj3QhDJrQDVDKUGppYxjU/TqNeFUAHMEozzQhNIapSuEPrHqJ3JRxiFSipKrWZLiWhAm82vI6OgOmSntNYCcD9HRM1VSl01ChZkhJ4SYQgmVhFWBLrNZD3yx2TLmwLX0TFMga/Q7/8gMxV1B7xNyPyLjhA2Dm6MaFT0sab/mUvYnMEdICO6AgyHBaGNmFScAVOyQehhVGzwkpZqjvekxqz2FIwKe2A8cY/k95iNByVxKqLWfEt0ph83EajPwxWrL16sb3ndbYsiIGBQhjEIYIO68cNdsE3o/uUMeRmyc9j2Fp84JHsOySZDHP57NyVoUcmds1gPvNvd8vb7mn/qf+LLb0oTiJJgnbE6CEbaJsE3I/YDtBmwYnYCUPBqaNeAZ26DLJuFjd6QcfIJFo2sSfUyswkSvE43Wjph51VRSzY6ToanAHBEVF/pLbxF/Hj5h3wOu2XAQcudVU9tk/vnyJ9639/yx/5E/NNfc5J5iQkqK7pTmzmjuIN5l9LY64/udm6E5InpmP3CMxZNgZpzW3UwPpYrYJ75ZXfOu2fJVvOFduGOtI2ZCyQGdZG+K4jYju8FrRLMfMHtRAmDp5ugUNdzZN3Bao2kT75otb+OWXidacVM0pkBJgiYIoxHGcihPpKN84IUJgAVrghU7jLjUxorV/kLulOkCpkvjj29u+dPqf7gM9wCEWsMexohtI/FW6K4yzU0iXu+wu/v9VIVN6UX+t1MsloSPwURqkuYV04t24Itwy0YHJouMtaFQsnpDJ+G95CHDODkBR0mZv+jLOublmKOfE4QKBG9t5k5IG4PLiX/ob/ky3PFOBwAmAre5Y9pFwp0StxC3mbCtDnkuTzxzLvApLFMT6qyPFUPmTpkI1kRKH5k2Au8H3r+/5V9WP/BNGAH4qSTu8iXXqUduI+210F4b8eoevbnH7rY+3LWPhpYxErlMEk5R+8zUAa8ShNhkVk1iHQaa6rAzSjEllYBMgk6eG0gq1Rk/b3X0l2I55ugRiIrPmYogbUPetExvWqZLePdmyzcXV3wdr+glEBC2peOv6S3fDRc0t0J7ZbQ35ZAdp/SwOLcQLJoEwMcfQ4AmktaR6UKZLoxvLq75180P/GO8opMGFeG69Hw/XfK3+zXNjdBdGe3NBPc7GAaPiI5LEwvB8kkQd8gWA6VVH/SK0MeJtY4EcbNSzNiVhtvcMaTo9aLJ25c2V0kXimWSMI9BhoD0HbJeYZue4V1g915Jbwp/6G74qrlhIyOTZe6s8JfxK/7r9it+vF7T3BjNdSLceeuSaTqMNy6MkGWSAE6ECNQ51NJFprWQLsBWmffNlndhSyOZicxg8P10wXfbDXkbae6NuE3IcGjWLCkiOsYiSZinsQkBaRqsayld9KJdC9pkGskECpMFtiVzUxquphV3Q4sMAU21cfPEc6S/BZYTotZpbKBOYTdI12KXa/Jlz/i2YXwD41ujX4+sdaSRzJ21fJsTf05f8uebL7j5YUNzpTR3Cd2lw0DXgrFITfCISN0hN2GvBaWD0hViKKgUghSyKXfWcFc67sYWBiUMPnFHev4Gza/BMjThdCchRug6pO/I65a0iaSVd9Gs9V5yMWVXGnY0/C1f8N/DV9zed4StEgbfypGZgOM51yfatvl78PIkzLtpKi58VVj1HhH1npwN7wLDGyWtC7JOdDExWeCudFzlNVd5xV/uv+D+uqe/UeIdhOlkfkgFMfGNm4URsSxzVJc0RAQLioWwb+hbxKcq1FAxsml1yi23qeMutTDJvpXJst3AA7ysJhyZIYkRaRuvlK56bNNTVg3TRpnWtZUZjRgKxYQf05rJAt+Ob/jr/SXf318gu0AYPUnbm6F56VDksPY0LwHCIjTi5Ug4MkOIr8fStEgM2Kojb1pyH5nWStoIqQeaggZf6vtpWjOUyP9u3/Lt9oLrbU+891amj8Mf3kfqihVmkDlsY86f41U2+h9ZkRWRQ0QUfSunzLtoATecc6PNhKEEoGWXI8MUSSm4CaqDXg/e55d8nlfX3pzzgRCQJroJ6jo3Q00kbzqmy0julbQSSgu57h2UIuzGhm+3bwha+O5uw83tirSL9IP4WEs2H50PgqgT68NjZb/5b0UflrNf0Dw9PwnHZmiOiELwBfG28cZNF5yATmpDv05di4+3TzlwPXaoGNtdRxoCDOpmaNaG+l42v89skh6YIl1EX+F5STjxAxKC36VB61ZmTc6iUKI8WOwDoAjFhJyVYYqIGDkpJO8n72dOrb7X8aXHuYIiWmtJp0S8gGl6PhKOE7J6QIjE6GdUxIj17oytCaRNIPVC7ny2yKL5qlMSyhgYi5CzC3XaNshO0UFqvcjfzoKfdXFsjgjlaFH8+LO9LBHPqgnzCIvUHgHHmhDUtaDRwx7aqSaYb96Q1GVoQBJkvk4tixyZIjl06XwJ8UgbXhhPT8Jjh4WEUCMhrSYo7gkorR5MUTgcFuJ7ZoKNiqlhuc6ZTuqL4fnUH1TyZk3I5aFJWhCeRxNODwtpIsToZep6VI4X6XxJPDe+EmuhCrLaeRkFAtW0+c91qA39SR5kyaZz1u0RkgTFki+jSykYn9CA35VPkBNn+IFW+GXqeYELrgpwXgSZYbO9l/1dLubaQcEXP2anfKQNnwOewRzV8tT+iIS5lFC/D/WAD5UHCRm4QDWDTbXwZvi+2vx7QCYIY60ZVccsxzfy8QElJ/jglC/4/eYJ+5nSo5NapBJgqp4h69GhUYKXoUvdxJ/qnV98W/NYyIfdg7qdX058Axx8wav2CTN+7i7b75aZC1xcwPMBL4WTG3reQ0t+ScaXxEvddzYOuw3wcEP/sSTthUoXz58xz61G8/6vlFLDzOLj60UO/kENTfUMo7qdszdXVV6SnTTN0GzNV6KGgu6ytzeHVIeA835J/NEpvFdXO6pzQDITIYKmgiRDOay6mroJKqFu6DzS/ZjNj+a6pT8UdChoPTTE5059NWpPwOkU3muooloxX+KTUk/SqjtlgIwRK05EDK4FkgM6+blEFqGE2afwwXE5syOWYg+OVNP7CcZpP/LClGq/+WnPLvo1eFoSzJiDd49u5se5HrUpPpilgjYNetVAUGIMh2M2VQ/9v9Ne8fwe9dhNmXy6gpyx3eBmaKoLIfVsu6c+XvPX4Ok1Yf/PlnrmBH66YjGPVuYO2JSgmZjHHqXmEHOp4QEei3KKudDrcTk2jIeDBFN68b20T+H5fMKxVhQFsjfeZzLmw2DnVuR8AvCpwE8SwAdmJSU/JMpsvxT4YDNzoXiZELUeMmpHMef+/vzIArn/6tNx/lKSr/8vXn7k5VRInzgF9oOb+VgrPgNhfwwvT8Lfg89Y8MdY1tzRK8WZhAXgTMICcCZhATiTsACILXmj7pXgrAkLwJmEBeBMwgJwJmEBOJOwAJxJWADOJCwAZxIWgDMJC8D/AaFVGQF9ub5yAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 100x100 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path.ls()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHv1JXA7zdAp",
        "outputId": "40e00baf-0c4f-43d6-8dfe-c1b2a9fbc8e6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('training'),Path('testing')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating tensors out of the randomly selcted val set\n",
        "valid_1_tens = torch.stack([tensor(Image.open(o)) \n",
        "                            for o in val_1])\n",
        "valid_1_tens = valid_1_tens.float()/255\n",
        "valid_7_tens = torch.stack([tensor(Image.open(o)) \n",
        "                            for o in val_7])\n",
        "valid_7_tens = valid_7_tens.float()/255\n"
      ],
      "metadata": {
        "id": "xNfLlr0kzST9"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mnist_distance(a,b): return ((a-b)**2).mean((-1,-2)).sqrt()\n",
        "def is_zoophilia_really_a_crime_when_thedonkeycantsayno(x): return mnist_distance(x,mean1) < mnist_distance(x,mean7)"
      ],
      "metadata": {
        "id": "cgz3NP9l3wmZ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_zoophilia_really_a_crime_when_thedonkeycantsayno(tit7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTIDWYCk4Tfx",
        "outputId": "2e896869-c9b9-405a-f8be-b14e76b2615c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(False)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating accuracy\n",
        "accuracy_1s =      is_zoophilia_really_a_crime_when_thedonkeycantsayno(valid_1_tens).float() .mean()\n",
        "accuracy_7s = (1 - is_zoophilia_really_a_crime_when_thedonkeycantsayno(valid_7_tens).float()).mean()\n",
        "\n",
        "accuracy_1s, accuracy_7s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8le1VPGH5Yq-",
        "outputId": "4de1b2ec-0a37-4f87-f433-723f9b7c77dc"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.9948), tensor(0.9218))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stochastic Gradient Descent (SGD)\n",
        "\n",
        "For this exercise I ask you to read the chapter Stochastic Gradient Descent (SGD) from the Google Colab 04_mnist_basics.ipynb in paralell. The chapter starts with a single TLU, compare p. 304 in \"Hands on Machine Learning\". Go through all 7 steps which are an easy example of how Stochastic Gradient Descent works.\n",
        "\n",
        "Our goal is to train a single TLU, which can decide if one number is larger then the other one. Therefore we create 100 random pairs with pyTorch and create a target vector which is eather 1 or 0.\n"
      ],
      "metadata": {
        "id": "ETcE9B9rdcEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn((100, 2))\n",
        "y = torch.where(x[:,0] > x[:,1], 1.0, 0.0)\n",
        "print(x[1][0])\n",
        "#print(y)\n",
        "len(x)"
      ],
      "metadata": {
        "id": "17qLyDnbpSbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b515375-9619-4fcd-a6d4-1f5e4ffa4514"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.1844)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your task is to create a function f that is a single TLU, meaning that it summarizes x with weights a, b, c:\n",
        "\n",
        "$ax_0+bx_1+c$\n",
        "\n",
        "In Addition we are using a *sigmoid()* function as step function.\n",
        "\n",
        "$f = \\text{sigmoid}(ax_0+bx_1+c)$"
      ],
      "metadata": {
        "id": "z267w4G48rxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sig(x):\n",
        " return 1/(1 + np.exp(-x))\n",
        "\n",
        "def f(x, params):\n",
        "    a,b,c = params\n",
        "    z = a*x[:,0]+b*x[:,1]+c\n",
        "    #fu = (a*i[0] + b*i[1] + c for i in x)\n",
        "    huso = sigmoid(z)\n",
        "    #print(huso)\n",
        "\n",
        "    \n",
        "    return huso\n",
        "\n",
        "print(f(x, [3,-2,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_NvBnCGoLPx",
        "outputId": "fdfeb4cb-ef96-4d72-d07a-2893b3ba3105"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6.7449e-01, 9.9654e-01, 5.0345e-01, 5.1828e-01, 6.9750e-01, 9.0508e-01, 1.3168e-01, 7.9255e-01, 9.8139e-01, 9.8705e-01, 7.8095e-01, 9.8876e-01, 9.8962e-01, 2.7235e-01, 6.4133e-01, 1.7626e-01,\n",
            "        3.3150e-01, 1.0977e-04, 9.4277e-01, 5.3911e-01, 5.9857e-02, 9.3990e-01, 9.4742e-01, 9.9950e-01, 7.1300e-01, 2.1885e-02, 6.8771e-01, 9.7712e-03, 1.2041e-03, 8.9504e-01, 7.9291e-01, 8.0544e-01,\n",
            "        9.9982e-01, 9.4001e-01, 3.4814e-01, 9.5772e-01, 2.1810e-02, 4.1523e-02, 9.6565e-01, 9.4814e-01, 3.6297e-01, 2.6368e-01, 9.4588e-01, 6.7875e-01, 9.9701e-01, 9.9259e-01, 4.8350e-01, 1.2513e-01,\n",
            "        1.4631e-02, 9.8481e-01, 5.9125e-02, 9.5812e-01, 3.1832e-01, 9.4329e-01, 9.6744e-01, 2.1413e-01, 1.6592e-01, 9.4139e-01, 9.4731e-01, 9.5023e-01, 7.2259e-01, 5.5343e-01, 4.4098e-02, 9.6697e-01,\n",
            "        4.7114e-03, 2.5552e-02, 6.4599e-02, 8.8854e-01, 1.7862e-01, 6.7821e-03, 1.4411e-01, 7.3790e-01, 9.0125e-01, 9.3024e-02, 3.6213e-01, 6.5427e-02, 9.9021e-01, 8.1112e-01, 2.0012e-01, 8.6082e-01,\n",
            "        9.9402e-01, 3.0444e-02, 8.2736e-01, 1.3512e-01, 8.9904e-01, 9.5687e-01, 1.8017e-01, 9.8431e-01, 2.6582e-02, 2.3109e-02, 5.2807e-02, 8.9113e-03, 9.4528e-01, 3.9498e-02, 1.6235e-02, 7.9366e-01,\n",
            "        6.2870e-03, 5.3804e-03, 1.0662e-01, 3.4538e-01])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition to our TLU function, we need a loss function. Your task is to implement a absolute difference loss function, $∑|x_i-y_i|$, which counts the number of wrong guesses."
      ],
      "metadata": {
        "id": "UBiKkGKx-jVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mae(preds, targets): return (preds-targets).abs().mean()"
      ],
      "metadata": {
        "id": "cwzyy281wI7Q"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to train your single TLU with the absolute difference loss function, use the following code. Choose an appropriate step weight `lr` and try to explain what is happing in each line."
      ],
      "metadata": {
        "id": "eGVNErmbvFxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-5\n",
        "params = torch.randn(3).requires_grad_()\n",
        "\n",
        "def apply_step(params, prn=True):\n",
        "    preds = f(x, params)\n",
        "    loss = mae(preds, y)\n",
        "    #print(loss)\n",
        "    loss.backward()\n",
        "    params.data -= lr * params.grad.data\n",
        "    params.grad = None\n",
        "    if prn: print(params);print(loss.item())\n",
        "    return preds\n",
        "\n",
        "\n",
        "for i in range(50): apply_step(params)"
      ],
      "metadata": {
        "id": "EB5TYTNmyO3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c6ad67-3d14-48c6-b04f-47f689e0ae32"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715975880622864\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715974688529968\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.37159737944602966\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.37159720063209534\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715971112251282\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.37159693241119385\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715968430042267\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715967535972595\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715966045856476\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.37159645557403564\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715963363647461\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.37159621715545654\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715960681438446\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.37159591913223267\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715957701206207\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.37159568071365356\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715955317020416\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715954124927521\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715952932834625\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715951442718506\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.37159502506256104\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.37159493565559387\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.37159478664398193\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715946674346924\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.37159451842308044\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715943992137909\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.37159425020217896\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.37159407138824463\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.37159401178359985\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715938627719879\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.371593713760376\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715936243534088\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.37159350514411926\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.37159332633018494\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715932071208954\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.37159308791160583\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715929687023163\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.37159281969070435\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715927004814148\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.37159261107444763\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715924322605133\n",
            "tensor([ 0.9733, -0.0913, -0.9899], requires_grad=True)\n",
            "0.37159228324890137\n",
            "tensor([ 0.9734, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715921640396118\n",
            "tensor([ 0.9734, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715920150279999\n",
            "tensor([ 0.9734, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715919256210327\n",
            "tensor([ 0.9734, -0.0913, -0.9899], requires_grad=True)\n",
            "0.37159180641174316\n",
            "tensor([ 0.9734, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715916872024536\n",
            "tensor([ 0.9734, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715915381908417\n",
            "tensor([ 0.9734, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715914189815521\n",
            "tensor([ 0.9734, -0.0913, -0.9899], requires_grad=True)\n",
            "0.3715912699699402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a line of code that counts the number of wrong predictions, rounding your predictions with *round()*."
      ],
      "metadata": {
        "id": "h5_LNc1o_o2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = f(x, params)\n",
        "rp = preds.round()\n",
        "\n",
        "print((y-rp).abs().sum())"
      ],
      "metadata": {
        "id": "EEUhyhyDxwMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29d98592-4fd5-4454-c4ec-192c5a957ac0"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(34., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    }
  ]
}